{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftdXWyhZ5w5g",
        "outputId": "71883e9f-a6b9-4c95-e7f2-7f125062b9b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic training data saved.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# Parameters\n",
        "num_samples = 100000  # Number of synthetic data points\n",
        "kp = 0.5  # Proportional gain for speed control\n",
        "max_throttle = 0.7\n",
        "max_brake = 1.0\n",
        "epsilon = 1e-3  # Small value to prevent division by zero\n",
        "target_distance = 10.0  # Desired distance in meters\n",
        "\n",
        "def normalize_angle(angle):\n",
        "    while angle > math.pi:\n",
        "        angle -= 2.0 * math.pi\n",
        "    while angle < -math.pi:\n",
        "        angle += 2.0 * math.pi\n",
        "    return angle\n",
        "\n",
        "# Generate synthetic data\n",
        "data = []\n",
        "for _ in range(num_samples):\n",
        "    # Randomly sample input values\n",
        "    lead_speed = np.random.uniform(0, 30)  # Lead vehicle speed (m/s)\n",
        "    follower_speed = np.random.uniform(0, 30)  # Follower vehicle speed (m/s)\n",
        "    lead_yaw = np.random.uniform(-math.pi, math.pi)  # Lead vehicle yaw (radians)\n",
        "    follower_yaw = np.random.uniform(-math.pi, math.pi)  # Follower vehicle yaw (radians)\n",
        "    distance = np.random.uniform(5, 20)  # Distance between vehicles (m)\n",
        "\n",
        "    # Compute desired speed and control outputs\n",
        "    speed_error = (distance - target_distance)\n",
        "    desired_speed = lead_speed + kp * speed_error\n",
        "    throttle = min(max_throttle, (desired_speed - follower_speed) / (desired_speed + epsilon)) if desired_speed > follower_speed else 0\n",
        "    brake = min(max_brake, (follower_speed - desired_speed) / (follower_speed + epsilon)) if desired_speed < follower_speed else 0\n",
        "\n",
        "    # Compute steering control\n",
        "    yaw_error = normalize_angle(lead_yaw - follower_yaw)\n",
        "    steer = max(-1.0, min(1.0, yaw_error * kp))\n",
        "\n",
        "    # Store the data point\n",
        "    data.append([lead_speed, follower_speed, lead_yaw, follower_yaw, throttle, brake, steer])\n",
        "\n",
        "# Save to a CSV file\n",
        "df = pd.DataFrame(data, columns=[\"lead_speed\", \"follower_speed\", \"lead_yaw\", \"follower_yaw\", \"throttle\", \"brake\", \"steer\"])\n",
        "df.to_csv(\"synthetic_training_data.csv\", index=False)\n",
        "print(\"Synthetic training data saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import json\n",
        "\n",
        "# Load synthetic data\n",
        "df = pd.read_csv(\"synthetic_training_data.csv\")\n",
        "X = df[[\"lead_speed\", \"follower_speed\", \"lead_yaw\", \"follower_yaw\"]].values\n",
        "y = df[[\"throttle\", \"brake\", \"steer\"]].values\n",
        "\n",
        "# Scale inputs and outputs for normalized range [0, 1]\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an MLP regressor\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(16, 8), activation='relu', max_iter=1000, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Save the model's weights and biases\n",
        "model_data = {\n",
        "    \"coefs\": [coef.tolist() for coef in mlp.coefs_],\n",
        "    \"intercepts\": [intercept.tolist() for intercept in mlp.intercepts_],\n",
        "    \"scaler_X_min\": scaler_X.min_.tolist(),\n",
        "    \"scaler_X_scale\": scaler_X.scale_.tolist(),\n",
        "    \"scaler_y_min\": scaler_y.min_.tolist(),\n",
        "    \"scaler_y_scale\": scaler_y.scale_.tolist()\n",
        "}\n",
        "\n",
        "with open(\"mlp_model.json\", \"w\") as f:\n",
        "    json.dump(model_data, f)\n",
        "\n",
        "print(\"Model trained and exported.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enh8RDpY8O-8",
        "outputId": "6f92cd10-2650-425d-bfc2-658ce2ff1c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and exported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "# Load synthetic data\n",
        "df = pd.read_csv(\"synthetic_training_data.csv\")\n",
        "X = df[[\"lead_speed\", \"follower_speed\", \"lead_yaw\", \"follower_yaw\"]].values\n",
        "y = df[[\"throttle\", \"brake\", \"steer\"]].values\n",
        "\n",
        "# Scale inputs and outputs for normalized range [0, 1]\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an MLP regressor with robust settings\n",
        "mlp = MLPRegressor(\n",
        "    hidden_layer_sizes=(32, 16),  # More neurons for robustness\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    learning_rate='adaptive',\n",
        "    max_iter=10000,\n",
        "    random_state=42,\n",
        "    verbose=True  # Display loss during training\n",
        ")\n",
        "\n",
        "# Fit the model and monitor performance\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate performance on the test set\n",
        "y_pred_scaled = mlp.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred_scaled)\n",
        "mae = mean_absolute_error(y_test, y_pred_scaled)\n",
        "print(f\"Test MSE: {mse:.6f}, Test MAE: {mae:.6f}\")\n",
        "\n",
        "# Rescale predictions back to original range\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_test_original = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Display predictions vs. ground truth\n",
        "for i in range(5):  # Display first 5 test samples\n",
        "    print(f\"Ground Truth: {y_test_original[i]}, Prediction: {y_pred[i]}\")\n",
        "\n",
        "# # Visualize predictions vs. ground truth\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(y_test_original[:, 0], label='Ground Truth Throttle', color='blue', alpha=0.7)\n",
        "# plt.plot(y_pred[:, 0], label='Predicted Throttle', color='red', linestyle='dashed', alpha=0.7)\n",
        "# plt.title(\"Throttle Predictions vs Ground Truth\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(y_test_original[:, 1], label='Ground Truth Brake', color='blue', alpha=0.7)\n",
        "# plt.plot(y_pred[:, 1], label='Predicted Brake', color='red', linestyle='dashed', alpha=0.7)\n",
        "# plt.title(\"Brake Predictions vs Ground Truth\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(y_test_original[:, 2], label='Ground Truth Steer', color='blue', alpha=0.7)\n",
        "# plt.plot(y_pred[:, 2], label='Predicted Steer', color='red', linestyle='dashed', alpha=0.7)\n",
        "# plt.title(\"Steer Predictions vs Ground Truth\")\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "\n",
        "# Export the model for deployment\n",
        "model_data = {\n",
        "    \"coefs\": [coef.tolist() for coef in mlp.coefs_],\n",
        "    \"intercepts\": [intercept.tolist() for intercept in mlp.intercepts_],\n",
        "    \"scaler_X_min\": scaler_X.min_.tolist(),\n",
        "    \"scaler_X_scale\": scaler_X.scale_.tolist(),\n",
        "    \"scaler_y_min\": scaler_y.min_.tolist(),\n",
        "    \"scaler_y_scale\": scaler_y.scale_.tolist()\n",
        "}\n",
        "\n",
        "with open(\"mlp_model.json\", \"w\") as f:\n",
        "    json.dump(model_data, f)\n",
        "\n",
        "print(\"Model trained, evaluated, and exported.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JtvkiNQ8poU",
        "outputId": "1a491237-a8b3-42c9-b8e1-2f69eb422a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.04774215\n",
            "Iteration 2, loss = 0.02390364\n",
            "Iteration 3, loss = 0.01525778\n",
            "Iteration 4, loss = 0.01240762\n",
            "Iteration 5, loss = 0.01102800\n",
            "Iteration 6, loss = 0.00953356\n",
            "Iteration 7, loss = 0.00831228\n",
            "Iteration 8, loss = 0.00743677\n",
            "Iteration 9, loss = 0.00673367\n",
            "Iteration 10, loss = 0.00615976\n",
            "Iteration 11, loss = 0.00570508\n",
            "Iteration 12, loss = 0.00538084\n",
            "Iteration 13, loss = 0.00512845\n",
            "Iteration 14, loss = 0.00495983\n",
            "Iteration 15, loss = 0.00481580\n",
            "Iteration 16, loss = 0.00471171\n",
            "Iteration 17, loss = 0.00460580\n",
            "Iteration 18, loss = 0.00452062\n",
            "Iteration 19, loss = 0.00445426\n",
            "Iteration 20, loss = 0.00440350\n",
            "Iteration 21, loss = 0.00435533\n",
            "Iteration 22, loss = 0.00429469\n",
            "Iteration 23, loss = 0.00424084\n",
            "Iteration 24, loss = 0.00417389\n",
            "Iteration 25, loss = 0.00414038\n",
            "Iteration 26, loss = 0.00410795\n",
            "Iteration 27, loss = 0.00407482\n",
            "Iteration 28, loss = 0.00406163\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Test MSE: 0.007849, Test MAE: 0.048200\n",
            "Ground Truth: [0.         0.09205998 1.        ], Prediction: [-0.01631376  0.20407691  1.09474252]\n",
            "Ground Truth: [ 0.          0.51351925 -0.90730339], Prediction: [-4.89272588e-04  5.88173223e-01 -8.94639306e-01]\n",
            "Ground Truth: [ 0.          0.22181808 -0.392317  ], Prediction: [ 0.00786267  0.33099388 -0.39600055]\n",
            "Ground Truth: [0.         0.05996952 0.16730946], Prediction: [0.01114977 0.12615113 0.15477229]\n",
            "Ground Truth: [0.00827814 0.         1.        ], Prediction: [0.02791634 0.08198357 1.05727114]\n",
            "Model trained, evaluated, and exported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Add\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Helper Functions\n",
        "def normalize_angle(angle):\n",
        "    \"\"\"Normalize an angle to the range [-pi, pi].\"\"\"\n",
        "    while angle > np.pi:\n",
        "        angle -= 2.0 * np.pi\n",
        "    while angle < -np.pi:\n",
        "        angle += 2.0 * np.pi\n",
        "    return angle\n",
        "\n",
        "# Generate Synthetic Training Data\n",
        "def generate_synthetic_data(num_samples=10000, target_distance=10.0, max_speed=30.0):\n",
        "    \"\"\"\n",
        "    Generate synthetic training data based on the platooning logic.\n",
        "    \"\"\"\n",
        "    lead_speeds = np.random.uniform(0, max_speed, num_samples)\n",
        "    follower_speeds = np.random.uniform(0, max_speed, num_samples)\n",
        "    lead_yaws = np.random.uniform(-np.pi, np.pi, num_samples)\n",
        "    follower_yaws = np.random.uniform(-np.pi, np.pi, num_samples)\n",
        "    distances = np.random.uniform(5, 20, num_samples)\n",
        "\n",
        "    # Calculate error terms\n",
        "    speed_errors = distances - target_distance\n",
        "    yaw_errors = [normalize_angle(lead_yaw - follower_yaw) for lead_yaw, follower_yaw in zip(lead_yaws, follower_yaws)]\n",
        "\n",
        "    # Desired outputs (throttle, brake, steer)\n",
        "    throttles = np.clip(speed_errors * 0.5, 0, 0.7)  # Linear relation for throttle\n",
        "    brakes = np.clip(-speed_errors * 0.1, 0, 1.0)    # Brake for overspeed\n",
        "    steers = np.clip(np.array(yaw_errors) * 0.5, -1.0, 1.0)  # Steer proportional to yaw error\n",
        "\n",
        "    # Combine inputs and outputs\n",
        "    inputs = np.column_stack((lead_speeds, follower_speeds, lead_yaws, follower_yaws, speed_errors, yaw_errors, distances))\n",
        "    outputs = np.column_stack((throttles, brakes, steers))\n",
        "    return inputs, outputs\n",
        "\n",
        "# Generate Data\n",
        "X, y = generate_synthetic_data()\n",
        "split_index = int(0.8 * len(X))\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "# Define MLP Architecture\n",
        "input_layer = Input(shape=(7,))\n",
        "dense1 = Dense(64, activation='relu')(input_layer)\n",
        "dense2 = Dense(32, activation='relu')(dense1)\n",
        "\n",
        "# Project input to match dense2 dimensions for residual connection\n",
        "projected_input = Dense(32, activation='linear')(input_layer)\n",
        "residual = Add()([projected_input, dense2])  # Skip connection\n",
        "\n",
        "dense3 = Dense(16, activation='relu')(residual)\n",
        "output_layer = Dense(3, activation='linear')(dense3)\n",
        "\n",
        "# Create and compile the model\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Custom Loss Function (Optional Gradient Matching)\n",
        "@tf.function\n",
        "def gradient_loss(y_true, y_pred, inputs):\n",
        "    grad_true = tf.gradients(y_true, inputs)[0]  # True gradient\n",
        "    grad_pred = tf.gradients(y_pred, inputs)[0]  # Predicted gradient\n",
        "    mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    grad_loss = tf.reduce_mean(tf.square(grad_true - grad_pred))\n",
        "    return mse_loss + grad_loss\n",
        "\n",
        "# Training the Model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=500,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plot Training and Validation Loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Training Loss vs Validation Loss\")\n",
        "plt.show()\n",
        "\n",
        "# Test the Model on New Data\n",
        "def test_model(model, num_samples=10):\n",
        "    \"\"\"\n",
        "    Test the model with new synthetic data.\n",
        "    \"\"\"\n",
        "    X_test, y_true = generate_synthetic_data(num_samples)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        print(f\"Input: {X_test[i]}\")\n",
        "        print(f\"True Output: {y_true[i]}\")\n",
        "        print(f\"Predicted Output: {y_pred[i]}\")\n",
        "        print('-' * 50)\n",
        "\n",
        "test_model(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qqBKjNSK9tEz",
        "outputId": "154cac14-fa76-47fd-d8b9-5e19256df93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m512\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m256\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m2,080\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m528\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │             \u001b[38;5;34m51\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,427\u001b[0m (13.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,427</span> (13.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,427\u001b[0m (13.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,427</span> (13.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.7489 - mae: 1.4213 - val_loss: 0.0908 - val_mae: 0.2342\n",
            "Epoch 2/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0681 - mae: 0.1961 - val_loss: 0.0387 - val_mae: 0.1497\n",
            "Epoch 3/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - mae: 0.1433 - val_loss: 0.0265 - val_mae: 0.1255\n",
            "Epoch 4/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0262 - mae: 0.1248 - val_loss: 0.0211 - val_mae: 0.1143\n",
            "Epoch 5/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0214 - mae: 0.1139 - val_loss: 0.0201 - val_mae: 0.1111\n",
            "Epoch 6/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0195 - mae: 0.1088 - val_loss: 0.0185 - val_mae: 0.1066\n",
            "Epoch 7/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0182 - mae: 0.1050 - val_loss: 0.0172 - val_mae: 0.1033\n",
            "Epoch 8/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0173 - mae: 0.1025 - val_loss: 0.0159 - val_mae: 0.0983\n",
            "Epoch 9/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0165 - mae: 0.0996 - val_loss: 0.0161 - val_mae: 0.0987\n",
            "Epoch 10/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.0978 - val_loss: 0.0155 - val_mae: 0.0965\n",
            "Epoch 11/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0161 - mae: 0.0980 - val_loss: 0.0143 - val_mae: 0.0924\n",
            "Epoch 12/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0153 - mae: 0.0952 - val_loss: 0.0141 - val_mae: 0.0920\n",
            "Epoch 13/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0147 - mae: 0.0929 - val_loss: 0.0135 - val_mae: 0.0890\n",
            "Epoch 14/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0142 - mae: 0.0908 - val_loss: 0.0137 - val_mae: 0.0891\n",
            "Epoch 15/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0896 - val_loss: 0.0132 - val_mae: 0.0888\n",
            "Epoch 16/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0136 - mae: 0.0885 - val_loss: 0.0123 - val_mae: 0.0855\n",
            "Epoch 17/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0859 - val_loss: 0.0131 - val_mae: 0.0883\n",
            "Epoch 18/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0125 - mae: 0.0849 - val_loss: 0.0111 - val_mae: 0.0794\n",
            "Epoch 19/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0838 - val_loss: 0.0110 - val_mae: 0.0808\n",
            "Epoch 20/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0115 - mae: 0.0809 - val_loss: 0.0103 - val_mae: 0.0764\n",
            "Epoch 21/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0110 - mae: 0.0787 - val_loss: 0.0106 - val_mae: 0.0765\n",
            "Epoch 22/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0111 - mae: 0.0796 - val_loss: 0.0098 - val_mae: 0.0746\n",
            "Epoch 23/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0103 - mae: 0.0761 - val_loss: 0.0108 - val_mae: 0.0808\n",
            "Epoch 24/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0104 - mae: 0.0766 - val_loss: 0.0097 - val_mae: 0.0734\n",
            "Epoch 25/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0098 - mae: 0.0735 - val_loss: 0.0110 - val_mae: 0.0765\n",
            "Epoch 26/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0737 - val_loss: 0.0106 - val_mae: 0.0755\n",
            "Epoch 27/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0096 - mae: 0.0719 - val_loss: 0.0093 - val_mae: 0.0729\n",
            "Epoch 28/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0093 - mae: 0.0709 - val_loss: 0.0096 - val_mae: 0.0732\n",
            "Epoch 29/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0096 - mae: 0.0714 - val_loss: 0.0089 - val_mae: 0.0688\n",
            "Epoch 30/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0097 - mae: 0.0720 - val_loss: 0.0113 - val_mae: 0.0749\n",
            "Epoch 31/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0700 - val_loss: 0.0120 - val_mae: 0.0794\n",
            "Epoch 32/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0102 - mae: 0.0722 - val_loss: 0.0081 - val_mae: 0.0661\n",
            "Epoch 33/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - mae: 0.0653 - val_loss: 0.0114 - val_mae: 0.0736\n",
            "Epoch 34/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0099 - mae: 0.0711 - val_loss: 0.0099 - val_mae: 0.0704\n",
            "Epoch 35/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0098 - mae: 0.0705 - val_loss: 0.0087 - val_mae: 0.0689\n",
            "Epoch 36/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0670 - val_loss: 0.0080 - val_mae: 0.0669\n",
            "Epoch 37/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0086 - mae: 0.0657 - val_loss: 0.0090 - val_mae: 0.0680\n",
            "Epoch 38/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0091 - mae: 0.0683 - val_loss: 0.0083 - val_mae: 0.0659\n",
            "Epoch 39/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0643 - val_loss: 0.0076 - val_mae: 0.0640\n",
            "Epoch 40/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - mae: 0.0654 - val_loss: 0.0083 - val_mae: 0.0624\n",
            "Epoch 41/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0080 - mae: 0.0636 - val_loss: 0.0076 - val_mae: 0.0604\n",
            "Epoch 42/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - mae: 0.0656 - val_loss: 0.0078 - val_mae: 0.0647\n",
            "Epoch 43/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0081 - mae: 0.0635 - val_loss: 0.0083 - val_mae: 0.0712\n",
            "Epoch 44/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0651 - val_loss: 0.0072 - val_mae: 0.0609\n",
            "Epoch 45/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0080 - mae: 0.0627 - val_loss: 0.0073 - val_mae: 0.0595\n",
            "Epoch 46/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - mae: 0.0600 - val_loss: 0.0067 - val_mae: 0.0551\n",
            "Epoch 47/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0065 - mae: 0.0560 - val_loss: 0.0060 - val_mae: 0.0542\n",
            "Epoch 48/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0063 - mae: 0.0547 - val_loss: 0.0058 - val_mae: 0.0507\n",
            "Epoch 49/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - mae: 0.0533 - val_loss: 0.0052 - val_mae: 0.0470\n",
            "Epoch 50/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0510 - val_loss: 0.0054 - val_mae: 0.0525\n",
            "Epoch 51/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0055 - mae: 0.0502 - val_loss: 0.0048 - val_mae: 0.0452\n",
            "Epoch 52/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0055 - mae: 0.0506 - val_loss: 0.0058 - val_mae: 0.0560\n",
            "Epoch 53/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0053 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0411\n",
            "Epoch 54/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0046 - mae: 0.0443 - val_loss: 0.0062 - val_mae: 0.0576\n",
            "Epoch 55/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0047 - mae: 0.0450 - val_loss: 0.0037 - val_mae: 0.0376\n",
            "Epoch 56/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0040 - mae: 0.0407 - val_loss: 0.0049 - val_mae: 0.0443\n",
            "Epoch 57/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0034 - mae: 0.0376 - val_loss: 0.0043 - val_mae: 0.0437\n",
            "Epoch 58/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mae: 0.0384 - val_loss: 0.0029 - val_mae: 0.0346\n",
            "Epoch 59/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0038 - mae: 0.0413 - val_loss: 0.0026 - val_mae: 0.0312\n",
            "Epoch 60/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0028 - mae: 0.0341 - val_loss: 0.0021 - val_mae: 0.0296\n",
            "Epoch 61/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0299 - val_loss: 0.0026 - val_mae: 0.0370\n",
            "Epoch 62/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0021 - mae: 0.0305 - val_loss: 0.0023 - val_mae: 0.0346\n",
            "Epoch 63/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0014 - val_mae: 0.0243\n",
            "Epoch 64/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0019 - val_mae: 0.0296\n",
            "Epoch 65/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0250 - val_loss: 0.0017 - val_mae: 0.0273\n",
            "Epoch 66/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0200\n",
            "Epoch 67/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0013 - mae: 0.0233 - val_loss: 0.0013 - val_mae: 0.0230\n",
            "Epoch 68/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mae: 0.0304 - val_loss: 0.0013 - val_mae: 0.0247\n",
            "Epoch 69/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 0.0011 - val_mae: 0.0214\n",
            "Epoch 70/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mae: 0.0249 - val_loss: 0.0014 - val_mae: 0.0239\n",
            "Epoch 71/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 0.0018 - val_mae: 0.0292\n",
            "Epoch 72/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0015 - val_mae: 0.0271\n",
            "Epoch 73/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0201 - val_loss: 0.0012 - val_mae: 0.0214\n",
            "Epoch 74/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0026 - val_mae: 0.0348\n",
            "Epoch 75/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0233 - val_loss: 0.0014 - val_mae: 0.0256\n",
            "Epoch 76/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 8.7551e-04 - val_mae: 0.0192\n",
            "Epoch 77/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0210 - val_loss: 0.0020 - val_mae: 0.0318\n",
            "Epoch 78/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0020 - mae: 0.0292 - val_loss: 7.7223e-04 - val_mae: 0.0172\n",
            "Epoch 79/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.9759e-04 - mae: 0.0201 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 80/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0207 - val_loss: 0.0017 - val_mae: 0.0293\n",
            "Epoch 81/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 6.7303e-04 - val_mae: 0.0153\n",
            "Epoch 82/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0200 - val_loss: 7.8750e-04 - val_mae: 0.0180\n",
            "Epoch 83/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 6.9979e-04 - val_mae: 0.0162\n",
            "Epoch 84/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.3350e-04 - mae: 0.0178 - val_loss: 6.0142e-04 - val_mae: 0.0143\n",
            "Epoch 85/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.4260e-04 - mae: 0.0181 - val_loss: 0.0014 - val_mae: 0.0244\n",
            "Epoch 86/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 8.7646e-04 - val_mae: 0.0190\n",
            "Epoch 87/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.3684e-04 - mae: 0.0195 - val_loss: 0.0012 - val_mae: 0.0230\n",
            "Epoch 88/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.9703e-04 - mae: 0.0171 - val_loss: 5.8350e-04 - val_mae: 0.0143\n",
            "Epoch 89/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6164e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 90/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.7964e-04 - mae: 0.0202 - val_loss: 5.6465e-04 - val_mae: 0.0145\n",
            "Epoch 91/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6606e-04 - mae: 0.0174 - val_loss: 9.2376e-04 - val_mae: 0.0204\n",
            "Epoch 92/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.4349e-04 - mae: 0.0176 - val_loss: 4.7673e-04 - val_mae: 0.0137\n",
            "Epoch 93/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 4.1813e-04 - val_mae: 0.0118\n",
            "Epoch 94/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.9976e-04 - mae: 0.0155 - val_loss: 4.6147e-04 - val_mae: 0.0132\n",
            "Epoch 95/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.8892e-04 - mae: 0.0168 - val_loss: 7.4066e-04 - val_mae: 0.0184\n",
            "Epoch 96/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.5506e-04 - mae: 0.0202 - val_loss: 5.2558e-04 - val_mae: 0.0152\n",
            "Epoch 97/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.8184e-04 - mae: 0.0156 - val_loss: 3.9548e-04 - val_mae: 0.0120\n",
            "Epoch 98/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.7779e-04 - mae: 0.0155 - val_loss: 0.0015 - val_mae: 0.0270\n",
            "Epoch 99/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.7622e-04 - mae: 0.0168 - val_loss: 4.5366e-04 - val_mae: 0.0137\n",
            "Epoch 100/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.8400e-04 - mae: 0.0157 - val_loss: 9.5581e-04 - val_mae: 0.0215\n",
            "Epoch 101/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.4749e-04 - mae: 0.0164 - val_loss: 4.7079e-04 - val_mae: 0.0141\n",
            "Epoch 102/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3397e-04 - mae: 0.0163 - val_loss: 5.3799e-04 - val_mae: 0.0151\n",
            "Epoch 103/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.9177e-04 - mae: 0.0172 - val_loss: 6.7165e-04 - val_mae: 0.0187\n",
            "Epoch 104/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.8862e-04 - mae: 0.0147 - val_loss: 7.0025e-04 - val_mae: 0.0174\n",
            "Epoch 105/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.7294e-04 - mae: 0.0198 - val_loss: 7.8241e-04 - val_mae: 0.0198\n",
            "Epoch 106/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.6116e-04 - mae: 0.0157 - val_loss: 4.3611e-04 - val_mae: 0.0151\n",
            "Epoch 107/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5106e-04 - mae: 0.0157 - val_loss: 4.3089e-04 - val_mae: 0.0140\n",
            "Epoch 108/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.4573e-04 - mae: 0.0151 - val_loss: 5.9691e-04 - val_mae: 0.0169\n",
            "Epoch 109/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0262e-04 - mae: 0.0158 - val_loss: 8.3166e-04 - val_mae: 0.0212\n",
            "Epoch 110/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4389e-04 - mae: 0.0204 - val_loss: 5.3220e-04 - val_mae: 0.0158\n",
            "Epoch 111/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9183e-04 - mae: 0.0146 - val_loss: 3.0757e-04 - val_mae: 0.0110\n",
            "Epoch 112/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6811e-04 - mae: 0.0145 - val_loss: 5.2907e-04 - val_mae: 0.0162\n",
            "Epoch 113/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.4993e-04 - mae: 0.0158 - val_loss: 4.9084e-04 - val_mae: 0.0159\n",
            "Epoch 114/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.8790e-04 - mae: 0.0160 - val_loss: 4.8225e-04 - val_mae: 0.0153\n",
            "Epoch 115/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6212e-04 - mae: 0.0127 - val_loss: 2.4347e-04 - val_mae: 0.0105\n",
            "Epoch 116/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.3670e-04 - mae: 0.0138 - val_loss: 2.1390e-04 - val_mae: 0.0096\n",
            "Epoch 117/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.3473e-04 - mae: 0.0118 - val_loss: 2.9711e-04 - val_mae: 0.0113\n",
            "Epoch 118/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.3622e-04 - mae: 0.0137 - val_loss: 4.2405e-04 - val_mae: 0.0142\n",
            "Epoch 119/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.9294e-04 - mae: 0.0153 - val_loss: 3.2871e-04 - val_mae: 0.0129\n",
            "Epoch 120/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7014e-04 - mae: 0.0129 - val_loss: 7.8803e-04 - val_mae: 0.0206\n",
            "Epoch 121/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.6929e-04 - mae: 0.0178 - val_loss: 6.3772e-04 - val_mae: 0.0191\n",
            "Epoch 122/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6382e-04 - mae: 0.0144 - val_loss: 3.2637e-04 - val_mae: 0.0117\n",
            "Epoch 123/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.0647e-04 - mae: 0.0118 - val_loss: 2.0284e-04 - val_mae: 0.0099\n",
            "Epoch 124/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5789e-04 - mae: 0.0108 - val_loss: 7.8789e-04 - val_mae: 0.0207\n",
            "Epoch 125/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.1977e-04 - mae: 0.0176 - val_loss: 1.4383e-04 - val_mae: 0.0075\n",
            "Epoch 126/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1622e-04 - mae: 0.0098 - val_loss: 1.8158e-04 - val_mae: 0.0090\n",
            "Epoch 127/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7293e-04 - mae: 0.0108 - val_loss: 2.9783e-04 - val_mae: 0.0107\n",
            "Epoch 128/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.3094e-04 - mae: 0.0100 - val_loss: 2.5699e-04 - val_mae: 0.0106\n",
            "Epoch 129/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5582e-04 - mae: 0.0126 - val_loss: 1.7967e-04 - val_mae: 0.0085\n",
            "Epoch 130/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6625e-04 - mae: 0.0124 - val_loss: 6.1833e-04 - val_mae: 0.0193\n",
            "Epoch 131/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.3949e-04 - mae: 0.0172 - val_loss: 1.9836e-04 - val_mae: 0.0096\n",
            "Epoch 132/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9604e-04 - mae: 0.0094 - val_loss: 1.5798e-04 - val_mae: 0.0089\n",
            "Epoch 133/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2025e-04 - mae: 0.0100 - val_loss: 1.2445e-04 - val_mae: 0.0068\n",
            "Epoch 134/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5602e-04 - mae: 0.0106 - val_loss: 7.1764e-04 - val_mae: 0.0176\n",
            "Epoch 135/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.1593e-04 - mae: 0.0120 - val_loss: 3.8134e-04 - val_mae: 0.0127\n",
            "Epoch 136/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0791e-04 - mae: 0.0115 - val_loss: 2.9681e-04 - val_mae: 0.0129\n",
            "Epoch 137/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9869e-04 - mae: 0.0159 - val_loss: 1.2833e-04 - val_mae: 0.0075\n",
            "Epoch 138/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3749e-04 - mae: 0.0107 - val_loss: 2.2109e-04 - val_mae: 0.0109\n",
            "Epoch 139/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.5088e-04 - mae: 0.0107 - val_loss: 5.9294e-04 - val_mae: 0.0164\n",
            "Epoch 140/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.9963e-04 - mae: 0.0166 - val_loss: 1.3597e-04 - val_mae: 0.0080\n",
            "Epoch 141/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.3568e-04 - mae: 0.0077 - val_loss: 1.2245e-04 - val_mae: 0.0069\n",
            "Epoch 142/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.9823e-04 - mae: 0.0116 - val_loss: 1.0716e-04 - val_mae: 0.0068\n",
            "Epoch 143/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.6539e-04 - mae: 0.0086 - val_loss: 7.9444e-05 - val_mae: 0.0055\n",
            "Epoch 144/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.0767e-04 - mae: 0.0114 - val_loss: 3.8762e-04 - val_mae: 0.0141\n",
            "Epoch 145/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.3827e-04 - mae: 0.0126 - val_loss: 1.6370e-04 - val_mae: 0.0089\n",
            "Epoch 146/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.4710e-04 - mae: 0.0106 - val_loss: 8.1356e-05 - val_mae: 0.0061\n",
            "Epoch 147/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.2746e-04 - mae: 0.0113 - val_loss: 2.9522e-04 - val_mae: 0.0129\n",
            "Epoch 148/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.6042e-04 - mae: 0.0111 - val_loss: 4.8129e-04 - val_mae: 0.0158\n",
            "Epoch 149/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8146e-04 - mae: 0.0109 - val_loss: 5.9927e-05 - val_mae: 0.0048\n",
            "Epoch 150/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.7129e-04 - mae: 0.0084 - val_loss: 1.7380e-04 - val_mae: 0.0088\n",
            "Epoch 151/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.8423e-04 - mae: 0.0124 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 152/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.1632e-04 - mae: 0.0097 - val_loss: 2.2529e-04 - val_mae: 0.0114\n",
            "Epoch 153/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7914e-04 - mae: 0.0127 - val_loss: 8.5757e-05 - val_mae: 0.0063\n",
            "Epoch 154/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.8708e-05 - mae: 0.0068 - val_loss: 1.1120e-04 - val_mae: 0.0078\n",
            "Epoch 155/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0917e-04 - mae: 0.0070 - val_loss: 2.0374e-04 - val_mae: 0.0099\n",
            "Epoch 156/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2443e-04 - mae: 0.0138 - val_loss: 3.0345e-04 - val_mae: 0.0116\n",
            "Epoch 157/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9392e-04 - mae: 0.0141 - val_loss: 6.8075e-05 - val_mae: 0.0061\n",
            "Epoch 158/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0948e-04 - mae: 0.0070 - val_loss: 2.3964e-04 - val_mae: 0.0111\n",
            "Epoch 159/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.9323e-04 - mae: 0.0112 - val_loss: 8.5161e-05 - val_mae: 0.0065\n",
            "Epoch 160/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6092e-04 - mae: 0.0085 - val_loss: 1.6065e-04 - val_mae: 0.0088\n",
            "Epoch 161/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.6642e-04 - mae: 0.0088 - val_loss: 9.1953e-04 - val_mae: 0.0202\n",
            "Epoch 162/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0234 - val_loss: 1.1799e-04 - val_mae: 0.0077\n",
            "Epoch 163/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.0642e-05 - mae: 0.0065 - val_loss: 7.2567e-05 - val_mae: 0.0058\n",
            "Epoch 164/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.3492e-05 - mae: 0.0063 - val_loss: 1.4374e-04 - val_mae: 0.0085\n",
            "Epoch 165/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.3902e-05 - mae: 0.0066 - val_loss: 2.1847e-04 - val_mae: 0.0099\n",
            "Epoch 166/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6496e-04 - mae: 0.0087 - val_loss: 9.2215e-04 - val_mae: 0.0206\n",
            "Epoch 167/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.2546e-04 - mae: 0.0174 - val_loss: 8.5572e-05 - val_mae: 0.0066\n",
            "Epoch 168/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.7051e-05 - mae: 0.0051 - val_loss: 1.8125e-04 - val_mae: 0.0098\n",
            "Epoch 169/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3121e-04 - mae: 0.0077 - val_loss: 4.7185e-05 - val_mae: 0.0048\n",
            "Epoch 170/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5751e-04 - mae: 0.0085 - val_loss: 2.0417e-04 - val_mae: 0.0095\n",
            "Epoch 171/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.6551e-04 - mae: 0.0108 - val_loss: 3.0478e-04 - val_mae: 0.0068\n",
            "Epoch 172/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6821e-04 - mae: 0.0088 - val_loss: 9.3165e-05 - val_mae: 0.0065\n",
            "Epoch 173/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1942e-04 - mae: 0.0073 - val_loss: 6.1233e-05 - val_mae: 0.0051\n",
            "Epoch 174/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1442e-04 - mae: 0.0070 - val_loss: 1.2930e-04 - val_mae: 0.0076\n",
            "Epoch 175/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0692e-04 - mae: 0.0069 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 176/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.3672e-04 - mae: 0.0168 - val_loss: 3.9969e-05 - val_mae: 0.0041\n",
            "Epoch 177/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1996e-04 - mae: 0.0075 - val_loss: 1.0426e-04 - val_mae: 0.0075\n",
            "Epoch 178/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4071e-04 - mae: 0.0080 - val_loss: 2.4313e-04 - val_mae: 0.0120\n",
            "Epoch 179/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8692e-04 - mae: 0.0093 - val_loss: 1.6008e-04 - val_mae: 0.0080\n",
            "Epoch 180/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5161e-04 - mae: 0.0078 - val_loss: 4.6543e-05 - val_mae: 0.0047\n",
            "Epoch 181/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.6557e-04 - mae: 0.0102 - val_loss: 1.7332e-04 - val_mae: 0.0091\n",
            "Epoch 182/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.0610e-04 - mae: 0.0099 - val_loss: 6.3183e-05 - val_mae: 0.0058\n",
            "Epoch 183/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.5694e-04 - mae: 0.0080 - val_loss: 1.2009e-04 - val_mae: 0.0079\n",
            "Epoch 184/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0628e-04 - mae: 0.0093 - val_loss: 1.4683e-04 - val_mae: 0.0084\n",
            "Epoch 185/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.5775e-05 - mae: 0.0055 - val_loss: 7.8609e-05 - val_mae: 0.0061\n",
            "Epoch 186/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5829e-04 - mae: 0.0126 - val_loss: 1.9286e-04 - val_mae: 0.0094\n",
            "Epoch 187/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2889e-04 - mae: 0.0076 - val_loss: 5.3521e-05 - val_mae: 0.0051\n",
            "Epoch 188/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.4084e-05 - mae: 0.0056 - val_loss: 1.0825e-04 - val_mae: 0.0073\n",
            "Epoch 189/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2962e-04 - mae: 0.0110 - val_loss: 2.4243e-04 - val_mae: 0.0113\n",
            "Epoch 190/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.7777e-04 - mae: 0.0088 - val_loss: 2.7724e-05 - val_mae: 0.0036\n",
            "Epoch 191/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.6275e-05 - mae: 0.0052 - val_loss: 3.4727e-04 - val_mae: 0.0145\n",
            "Epoch 192/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8569e-04 - mae: 0.0091 - val_loss: 5.5510e-04 - val_mae: 0.0169\n",
            "Epoch 193/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8033e-04 - mae: 0.0088 - val_loss: 5.1871e-04 - val_mae: 0.0148\n",
            "Epoch 194/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5255e-04 - mae: 0.0078 - val_loss: 5.8676e-05 - val_mae: 0.0054\n",
            "Epoch 195/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.5601e-05 - mae: 0.0057 - val_loss: 2.4503e-04 - val_mae: 0.0113\n",
            "Epoch 196/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.9659e-04 - mae: 0.0112 - val_loss: 4.3152e-04 - val_mae: 0.0136\n",
            "Epoch 197/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.8897e-04 - mae: 0.0169 - val_loss: 4.3345e-05 - val_mae: 0.0045\n",
            "Epoch 198/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4413e-05 - mae: 0.0039 - val_loss: 2.1726e-05 - val_mae: 0.0031\n",
            "Epoch 199/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2367e-05 - mae: 0.0039 - val_loss: 6.4466e-05 - val_mae: 0.0058\n",
            "Epoch 200/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.6660e-05 - mae: 0.0047 - val_loss: 1.1373e-04 - val_mae: 0.0077\n",
            "Epoch 201/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.5298e-05 - mae: 0.0067 - val_loss: 8.8226e-05 - val_mae: 0.0067\n",
            "Epoch 202/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.8441e-04 - mae: 0.0093 - val_loss: 1.1349e-04 - val_mae: 0.0067\n",
            "Epoch 203/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.4242e-04 - mae: 0.0120 - val_loss: 5.3251e-04 - val_mae: 0.0145\n",
            "Epoch 204/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4852e-04 - mae: 0.0077 - val_loss: 2.8355e-05 - val_mae: 0.0035\n",
            "Epoch 205/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.2245e-05 - mae: 0.0048 - val_loss: 3.7019e-04 - val_mae: 0.0139\n",
            "Epoch 206/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.9979e-04 - mae: 0.0107 - val_loss: 5.3198e-05 - val_mae: 0.0052\n",
            "Epoch 207/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.6569e-05 - mae: 0.0053 - val_loss: 3.9554e-05 - val_mae: 0.0044\n",
            "Epoch 208/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.5571e-05 - mae: 0.0040 - val_loss: 3.9774e-04 - val_mae: 0.0140\n",
            "Epoch 209/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8720e-04 - mae: 0.0085 - val_loss: 3.2389e-04 - val_mae: 0.0117\n",
            "Epoch 210/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3043e-04 - mae: 0.0098 - val_loss: 1.5518e-05 - val_mae: 0.0026\n",
            "Epoch 211/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5143e-05 - mae: 0.0034 - val_loss: 2.1605e-05 - val_mae: 0.0032\n",
            "Epoch 212/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5158e-05 - mae: 0.0045 - val_loss: 4.6609e-05 - val_mae: 0.0051\n",
            "Epoch 213/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3022e-05 - mae: 0.0052 - val_loss: 1.5533e-04 - val_mae: 0.0097\n",
            "Epoch 214/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7131e-04 - mae: 0.0105 - val_loss: 6.2620e-05 - val_mae: 0.0055\n",
            "Epoch 215/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9913e-05 - mae: 0.0048 - val_loss: 4.4163e-05 - val_mae: 0.0043\n",
            "Epoch 216/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.7270e-05 - mae: 0.0055 - val_loss: 2.3914e-04 - val_mae: 0.0108\n",
            "Epoch 217/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0429e-04 - mae: 0.0095 - val_loss: 4.5508e-05 - val_mae: 0.0050\n",
            "Epoch 218/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9596e-05 - mae: 0.0049 - val_loss: 2.1926e-05 - val_mae: 0.0034\n",
            "Epoch 219/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.6805e-05 - mae: 0.0064 - val_loss: 5.6808e-05 - val_mae: 0.0054\n",
            "Epoch 220/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.6990e-04 - mae: 0.0099 - val_loss: 6.0528e-05 - val_mae: 0.0051\n",
            "Epoch 221/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.1347e-05 - mae: 0.0050 - val_loss: 6.9035e-05 - val_mae: 0.0062\n",
            "Epoch 222/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.6183e-05 - mae: 0.0063 - val_loss: 2.1049e-04 - val_mae: 0.0105\n",
            "Epoch 223/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.9753e-04 - mae: 0.0147 - val_loss: 8.2855e-05 - val_mae: 0.0059\n",
            "Epoch 224/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.8033e-05 - mae: 0.0055 - val_loss: 1.7305e-04 - val_mae: 0.0076\n",
            "Epoch 225/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.4048e-04 - mae: 0.0094 - val_loss: 4.2995e-05 - val_mae: 0.0048\n",
            "Epoch 226/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.3700e-05 - mae: 0.0057 - val_loss: 1.1623e-04 - val_mae: 0.0077\n",
            "Epoch 227/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2547e-05 - mae: 0.0047 - val_loss: 1.3816e-04 - val_mae: 0.0082\n",
            "Epoch 228/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.4054e-04 - mae: 0.0149 - val_loss: 1.9046e-05 - val_mae: 0.0028\n",
            "Epoch 229/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3636e-05 - mae: 0.0033 - val_loss: 2.6682e-05 - val_mae: 0.0036\n",
            "Epoch 230/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7315e-05 - mae: 0.0047 - val_loss: 4.9086e-05 - val_mae: 0.0051\n",
            "Epoch 231/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2270e-04 - mae: 0.0070 - val_loss: 9.8899e-05 - val_mae: 0.0072\n",
            "Epoch 232/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1232e-04 - mae: 0.0060 - val_loss: 3.1348e-04 - val_mae: 0.0130\n",
            "Epoch 233/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.8880e-04 - mae: 0.0086 - val_loss: 1.7296e-05 - val_mae: 0.0027\n",
            "Epoch 234/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6300e-05 - mae: 0.0041 - val_loss: 4.2590e-05 - val_mae: 0.0046\n",
            "Epoch 235/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4965e-05 - mae: 0.0047 - val_loss: 1.7373e-05 - val_mae: 0.0028\n",
            "Epoch 236/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2648e-05 - mae: 0.0039 - val_loss: 7.8389e-05 - val_mae: 0.0060\n",
            "Epoch 237/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0995e-04 - mae: 0.0175 - val_loss: 8.3853e-05 - val_mae: 0.0068\n",
            "Epoch 238/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8820e-04 - mae: 0.0091 - val_loss: 4.3592e-05 - val_mae: 0.0046\n",
            "Epoch 239/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9116e-05 - mae: 0.0038 - val_loss: 1.6649e-05 - val_mae: 0.0028\n",
            "Epoch 240/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.3657e-05 - mae: 0.0033 - val_loss: 1.3741e-05 - val_mae: 0.0025\n",
            "Epoch 241/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.9008e-04 - mae: 0.0079 - val_loss: 1.3201e-04 - val_mae: 0.0084\n",
            "Epoch 242/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.1072e-05 - mae: 0.0058 - val_loss: 6.8586e-05 - val_mae: 0.0059\n",
            "Epoch 243/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0942e-05 - mae: 0.0038 - val_loss: 1.0448e-04 - val_mae: 0.0071\n",
            "Epoch 244/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.3128e-04 - mae: 0.0072 - val_loss: 1.4682e-04 - val_mae: 0.0086\n",
            "Epoch 245/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 3.2050e-04 - mae: 0.0112 - val_loss: 7.3897e-05 - val_mae: 0.0065\n",
            "Epoch 246/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4770e-05 - mae: 0.0050 - val_loss: 3.1538e-05 - val_mae: 0.0039\n",
            "Epoch 247/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.7141e-05 - mae: 0.0058 - val_loss: 2.5595e-05 - val_mae: 0.0035\n",
            "Epoch 248/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3230e-04 - mae: 0.0070 - val_loss: 6.5420e-04 - val_mae: 0.0171\n",
            "Epoch 249/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0477e-04 - mae: 0.0094 - val_loss: 2.6102e-05 - val_mae: 0.0033\n",
            "Epoch 250/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5190e-05 - mae: 0.0034 - val_loss: 2.6148e-05 - val_mae: 0.0037\n",
            "Epoch 251/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.0480e-05 - mae: 0.0047 - val_loss: 5.4964e-05 - val_mae: 0.0052\n",
            "Epoch 252/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6673e-04 - mae: 0.0106 - val_loss: 7.0012e-04 - val_mae: 0.0187\n",
            "Epoch 253/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.4980e-04 - mae: 0.0103 - val_loss: 3.9438e-05 - val_mae: 0.0045\n",
            "Epoch 254/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1021e-04 - mae: 0.0067 - val_loss: 7.9838e-05 - val_mae: 0.0060\n",
            "Epoch 255/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8290e-04 - mae: 0.0089 - val_loss: 4.8646e-05 - val_mae: 0.0051\n",
            "Epoch 256/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0371e-04 - mae: 0.0068 - val_loss: 1.1283e-05 - val_mae: 0.0022\n",
            "Epoch 257/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.6642e-05 - mae: 0.0041 - val_loss: 2.0563e-05 - val_mae: 0.0031\n",
            "Epoch 258/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6423e-05 - mae: 0.0035 - val_loss: 4.0462e-05 - val_mae: 0.0046\n",
            "Epoch 259/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5743e-05 - mae: 0.0065 - val_loss: 2.8155e-05 - val_mae: 0.0037\n",
            "Epoch 260/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0731e-04 - mae: 0.0068 - val_loss: 8.3851e-05 - val_mae: 0.0061\n",
            "Epoch 261/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6282e-04 - mae: 0.0080 - val_loss: 3.8551e-05 - val_mae: 0.0042\n",
            "Epoch 262/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6869e-05 - mae: 0.0059 - val_loss: 2.7633e-05 - val_mae: 0.0037\n",
            "Epoch 263/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2020e-04 - mae: 0.0059 - val_loss: 5.5119e-04 - val_mae: 0.0139\n",
            "Epoch 264/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4230e-04 - mae: 0.0116 - val_loss: 1.9070e-05 - val_mae: 0.0031\n",
            "Epoch 265/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.6877e-05 - mae: 0.0029 - val_loss: 5.4111e-05 - val_mae: 0.0055\n",
            "Epoch 266/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.7526e-05 - mae: 0.0062 - val_loss: 8.1594e-05 - val_mae: 0.0066\n",
            "Epoch 267/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.7086e-05 - mae: 0.0065 - val_loss: 8.8933e-05 - val_mae: 0.0069\n",
            "Epoch 268/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.5827e-04 - mae: 0.0081 - val_loss: 4.6706e-05 - val_mae: 0.0051\n",
            "Epoch 269/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.1399e-05 - mae: 0.0056 - val_loss: 2.5293e-05 - val_mae: 0.0035\n",
            "Epoch 270/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.4952e-05 - mae: 0.0053 - val_loss: 4.6773e-05 - val_mae: 0.0048\n",
            "Epoch 271/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9624e-05 - mae: 0.0048 - val_loss: 1.0300e-04 - val_mae: 0.0064\n",
            "Epoch 272/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6334e-04 - mae: 0.0081 - val_loss: 3.2195e-04 - val_mae: 0.0135\n",
            "Epoch 273/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4634e-04 - mae: 0.0078 - val_loss: 5.2291e-05 - val_mae: 0.0051\n",
            "Epoch 274/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4215e-05 - mae: 0.0036 - val_loss: 1.8785e-04 - val_mae: 0.0095\n",
            "Epoch 275/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.8488e-04 - mae: 0.0113 - val_loss: 2.7431e-04 - val_mae: 0.0120\n",
            "Epoch 276/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8440e-05 - mae: 0.0063 - val_loss: 2.3981e-05 - val_mae: 0.0036\n",
            "Epoch 277/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7244e-05 - mae: 0.0028 - val_loss: 1.2617e-05 - val_mae: 0.0025\n",
            "Epoch 278/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5898e-05 - mae: 0.0027 - val_loss: 2.1708e-05 - val_mae: 0.0033\n",
            "Epoch 279/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2047e-05 - mae: 0.0038 - val_loss: 6.4929e-05 - val_mae: 0.0051\n",
            "Epoch 280/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.3136e-05 - mae: 0.0045 - val_loss: 3.0345e-05 - val_mae: 0.0039\n",
            "Epoch 281/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0325e-05 - mae: 0.0029 - val_loss: 8.3986e-05 - val_mae: 0.0071\n",
            "Epoch 282/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.2490e-05 - mae: 0.0044 - val_loss: 2.9630e-05 - val_mae: 0.0038\n",
            "Epoch 283/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.6504e-05 - mae: 0.0041 - val_loss: 9.9843e-05 - val_mae: 0.0069\n",
            "Epoch 284/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6722e-04 - mae: 0.0109 - val_loss: 1.8437e-05 - val_mae: 0.0030\n",
            "Epoch 285/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.6346e-05 - mae: 0.0044 - val_loss: 2.4177e-04 - val_mae: 0.0097\n",
            "Epoch 286/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.8746e-04 - mae: 0.0109 - val_loss: 6.2325e-05 - val_mae: 0.0052\n",
            "Epoch 287/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.2025e-05 - mae: 0.0042 - val_loss: 3.7997e-05 - val_mae: 0.0043\n",
            "Epoch 288/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.1895e-05 - mae: 0.0062 - val_loss: 1.1363e-04 - val_mae: 0.0076\n",
            "Epoch 289/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.0655e-05 - mae: 0.0037 - val_loss: 3.9499e-05 - val_mae: 0.0047\n",
            "Epoch 290/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.2482e-04 - mae: 0.0069 - val_loss: 4.6979e-05 - val_mae: 0.0050\n",
            "Epoch 291/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.8069e-05 - mae: 0.0061 - val_loss: 2.1855e-05 - val_mae: 0.0033\n",
            "Epoch 292/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.6637e-05 - mae: 0.0055 - val_loss: 2.8858e-05 - val_mae: 0.0038\n",
            "Epoch 293/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2584e-04 - mae: 0.0067 - val_loss: 6.6506e-05 - val_mae: 0.0058\n",
            "Epoch 294/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.6681e-05 - mae: 0.0051 - val_loss: 9.6674e-05 - val_mae: 0.0065\n",
            "Epoch 295/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1926e-05 - mae: 0.0049 - val_loss: 2.9799e-05 - val_mae: 0.0036\n",
            "Epoch 296/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2419e-04 - mae: 0.0068 - val_loss: 2.0250e-04 - val_mae: 0.0093\n",
            "Epoch 297/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.9111e-05 - mae: 0.0065 - val_loss: 4.6049e-05 - val_mae: 0.0046\n",
            "Epoch 298/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0438e-04 - mae: 0.0065 - val_loss: 3.0976e-05 - val_mae: 0.0040\n",
            "Epoch 299/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9546e-05 - mae: 0.0049 - val_loss: 6.0372e-05 - val_mae: 0.0055\n",
            "Epoch 300/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.8507e-05 - mae: 0.0042 - val_loss: 3.5904e-05 - val_mae: 0.0041\n",
            "Epoch 301/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5941e-04 - mae: 0.0068 - val_loss: 3.8570e-05 - val_mae: 0.0042\n",
            "Epoch 302/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.6442e-05 - mae: 0.0048 - val_loss: 8.9097e-05 - val_mae: 0.0060\n",
            "Epoch 303/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.8618e-05 - mae: 0.0034 - val_loss: 2.2484e-05 - val_mae: 0.0035\n",
            "Epoch 304/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0180e-04 - mae: 0.0080 - val_loss: 4.4907e-05 - val_mae: 0.0049\n",
            "Epoch 305/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6526e-05 - mae: 0.0042 - val_loss: 2.8050e-05 - val_mae: 0.0038\n",
            "Epoch 306/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5826e-04 - mae: 0.0065 - val_loss: 1.6317e-04 - val_mae: 0.0090\n",
            "Epoch 307/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.6162e-05 - mae: 0.0046 - val_loss: 2.1596e-05 - val_mae: 0.0033\n",
            "Epoch 308/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2252e-05 - mae: 0.0024 - val_loss: 2.0036e-05 - val_mae: 0.0034\n",
            "Epoch 309/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.3261e-05 - mae: 0.0033 - val_loss: 1.1438e-05 - val_mae: 0.0022\n",
            "Epoch 310/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.4785e-05 - mae: 0.0040 - val_loss: 1.3318e-04 - val_mae: 0.0082\n",
            "Epoch 311/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0010e-04 - mae: 0.0070 - val_loss: 7.2089e-05 - val_mae: 0.0056\n",
            "Epoch 312/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.0983e-05 - mae: 0.0053 - val_loss: 1.4214e-05 - val_mae: 0.0026\n",
            "Epoch 313/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.4719e-05 - mae: 0.0058 - val_loss: 2.2539e-04 - val_mae: 0.0113\n",
            "Epoch 314/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2021e-04 - mae: 0.0117 - val_loss: 3.6918e-05 - val_mae: 0.0039\n",
            "Epoch 315/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1254e-05 - mae: 0.0032 - val_loss: 2.1472e-05 - val_mae: 0.0033\n",
            "Epoch 316/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.3730e-04 - mae: 0.0084 - val_loss: 1.5136e-05 - val_mae: 0.0028\n",
            "Epoch 317/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6809e-05 - mae: 0.0039 - val_loss: 1.3299e-04 - val_mae: 0.0086\n",
            "Epoch 318/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.8374e-05 - mae: 0.0047 - val_loss: 2.2345e-05 - val_mae: 0.0036\n",
            "Epoch 319/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0715e-05 - mae: 0.0031 - val_loss: 6.4767e-05 - val_mae: 0.0056\n",
            "Epoch 320/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1132e-04 - mae: 0.0097 - val_loss: 1.6449e-04 - val_mae: 0.0090\n",
            "Epoch 321/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.7941e-05 - mae: 0.0044 - val_loss: 1.3994e-05 - val_mae: 0.0027\n",
            "Epoch 322/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1299e-05 - mae: 0.0023 - val_loss: 1.3793e-05 - val_mae: 0.0028\n",
            "Epoch 323/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.3073e-05 - mae: 0.0050 - val_loss: 2.8427e-04 - val_mae: 0.0117\n",
            "Epoch 324/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1182e-05 - mae: 0.0051 - val_loss: 2.1562e-05 - val_mae: 0.0034\n",
            "Epoch 325/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0021e-04 - mae: 0.0066 - val_loss: 6.0144e-05 - val_mae: 0.0056\n",
            "Epoch 326/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5879e-05 - mae: 0.0033 - val_loss: 1.2016e-04 - val_mae: 0.0084\n",
            "Epoch 327/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.7694e-05 - mae: 0.0062 - val_loss: 2.9528e-05 - val_mae: 0.0041\n",
            "Epoch 328/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2454e-04 - mae: 0.0067 - val_loss: 1.0238e-04 - val_mae: 0.0079\n",
            "Epoch 329/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.9387e-05 - mae: 0.0037 - val_loss: 1.5367e-05 - val_mae: 0.0028\n",
            "Epoch 330/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5538e-04 - mae: 0.0070 - val_loss: 5.7514e-05 - val_mae: 0.0050\n",
            "Epoch 331/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8965e-05 - mae: 0.0042 - val_loss: 7.9235e-05 - val_mae: 0.0059\n",
            "Epoch 332/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.2723e-05 - mae: 0.0046 - val_loss: 0.0014 - val_mae: 0.0283\n",
            "Epoch 333/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.6745e-04 - mae: 0.0135 - val_loss: 7.2787e-05 - val_mae: 0.0060\n",
            "Epoch 334/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.7201e-05 - mae: 0.0047 - val_loss: 3.3910e-05 - val_mae: 0.0046\n",
            "Epoch 335/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.7536e-05 - mae: 0.0044 - val_loss: 9.5318e-05 - val_mae: 0.0069\n",
            "Epoch 336/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.0109e-05 - mae: 0.0055 - val_loss: 1.0073e-05 - val_mae: 0.0021\n",
            "Epoch 337/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7802e-05 - mae: 0.0035 - val_loss: 4.4488e-05 - val_mae: 0.0047\n",
            "Epoch 338/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.8883e-05 - mae: 0.0036 - val_loss: 1.5436e-05 - val_mae: 0.0029\n",
            "Epoch 339/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0264e-04 - mae: 0.0062 - val_loss: 5.9394e-05 - val_mae: 0.0056\n",
            "Epoch 340/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.5557e-05 - mae: 0.0062 - val_loss: 1.0139e-05 - val_mae: 0.0020\n",
            "Epoch 341/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.2829e-05 - mae: 0.0046 - val_loss: 4.7164e-05 - val_mae: 0.0053\n",
            "Epoch 342/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5212e-04 - mae: 0.0076 - val_loss: 3.0310e-04 - val_mae: 0.0126\n",
            "Epoch 343/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.2331e-04 - mae: 0.0095 - val_loss: 3.2544e-05 - val_mae: 0.0040\n",
            "Epoch 344/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.8040e-05 - mae: 0.0036 - val_loss: 9.9338e-06 - val_mae: 0.0024\n",
            "Epoch 345/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.6618e-05 - mae: 0.0038 - val_loss: 5.8807e-04 - val_mae: 0.0183\n",
            "Epoch 346/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0633e-04 - mae: 0.0095 - val_loss: 1.4797e-05 - val_mae: 0.0025\n",
            "Epoch 347/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8710e-05 - mae: 0.0035 - val_loss: 1.1443e-04 - val_mae: 0.0071\n",
            "Epoch 348/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0288e-04 - mae: 0.0060 - val_loss: 1.3739e-04 - val_mae: 0.0093\n",
            "Epoch 349/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2666e-04 - mae: 0.0076 - val_loss: 1.2683e-04 - val_mae: 0.0074\n",
            "Epoch 350/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5103e-05 - mae: 0.0050 - val_loss: 1.1967e-04 - val_mae: 0.0072\n",
            "Epoch 351/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.5126e-04 - mae: 0.0097 - val_loss: 1.3822e-05 - val_mae: 0.0027\n",
            "Epoch 352/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.6401e-05 - mae: 0.0033 - val_loss: 1.1881e-05 - val_mae: 0.0026\n",
            "Epoch 353/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5322e-05 - mae: 0.0026 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 354/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.9291e-04 - mae: 0.0108 - val_loss: 2.1979e-05 - val_mae: 0.0034\n",
            "Epoch 355/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.6053e-05 - mae: 0.0040 - val_loss: 3.6605e-05 - val_mae: 0.0043\n",
            "Epoch 356/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.4172e-05 - mae: 0.0055 - val_loss: 1.9372e-05 - val_mae: 0.0033\n",
            "Epoch 357/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.7835e-05 - mae: 0.0052 - val_loss: 8.6617e-05 - val_mae: 0.0062\n",
            "Epoch 358/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5651e-04 - mae: 0.0080 - val_loss: 1.1746e-05 - val_mae: 0.0024\n",
            "Epoch 359/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2368e-05 - mae: 0.0023 - val_loss: 1.3803e-05 - val_mae: 0.0025\n",
            "Epoch 360/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.3531e-05 - mae: 0.0032 - val_loss: 1.8377e-04 - val_mae: 0.0082\n",
            "Epoch 361/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7090e-04 - mae: 0.0106 - val_loss: 4.5888e-05 - val_mae: 0.0042\n",
            "Epoch 362/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.0962e-05 - mae: 0.0040 - val_loss: 1.2719e-05 - val_mae: 0.0028\n",
            "Epoch 363/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2726e-05 - mae: 0.0025 - val_loss: 2.2370e-05 - val_mae: 0.0033\n",
            "Epoch 364/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.5577e-05 - mae: 0.0055 - val_loss: 2.8996e-05 - val_mae: 0.0035\n",
            "Epoch 365/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0882e-04 - mae: 0.0070 - val_loss: 1.2002e-05 - val_mae: 0.0025\n",
            "Epoch 366/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.8005e-05 - mae: 0.0050 - val_loss: 1.6741e-04 - val_mae: 0.0101\n",
            "Epoch 367/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6926e-04 - mae: 0.0083 - val_loss: 2.1863e-05 - val_mae: 0.0033\n",
            "Epoch 368/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.8957e-05 - mae: 0.0043 - val_loss: 1.2140e-05 - val_mae: 0.0025\n",
            "Epoch 369/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8687e-05 - mae: 0.0048 - val_loss: 2.3333e-04 - val_mae: 0.0096\n",
            "Epoch 370/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7415e-05 - mae: 0.0051 - val_loss: 1.4412e-05 - val_mae: 0.0027\n",
            "Epoch 371/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6120e-05 - mae: 0.0031 - val_loss: 3.7272e-05 - val_mae: 0.0040\n",
            "Epoch 372/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7211e-05 - mae: 0.0033 - val_loss: 8.1151e-05 - val_mae: 0.0063\n",
            "Epoch 373/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5643e-04 - mae: 0.0079 - val_loss: 3.3442e-05 - val_mae: 0.0042\n",
            "Epoch 374/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.6316e-05 - mae: 0.0027 - val_loss: 8.7993e-06 - val_mae: 0.0019\n",
            "Epoch 375/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.6050e-05 - mae: 0.0027 - val_loss: 8.9056e-05 - val_mae: 0.0066\n",
            "Epoch 376/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.3393e-04 - mae: 0.0074 - val_loss: 7.4728e-05 - val_mae: 0.0067\n",
            "Epoch 377/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.4654e-04 - mae: 0.0083 - val_loss: 1.5595e-05 - val_mae: 0.0032\n",
            "Epoch 378/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.2871e-05 - mae: 0.0033 - val_loss: 1.1749e-05 - val_mae: 0.0025\n",
            "Epoch 379/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.1441e-05 - mae: 0.0031 - val_loss: 8.0513e-05 - val_mae: 0.0062\n",
            "Epoch 380/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4150e-05 - mae: 0.0056 - val_loss: 3.7651e-05 - val_mae: 0.0039\n",
            "Epoch 381/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.1688e-05 - mae: 0.0058 - val_loss: 7.6546e-05 - val_mae: 0.0059\n",
            "Epoch 382/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.9687e-05 - mae: 0.0055 - val_loss: 3.2581e-05 - val_mae: 0.0037\n",
            "Epoch 383/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4568e-04 - mae: 0.0069 - val_loss: 2.5525e-05 - val_mae: 0.0035\n",
            "Epoch 384/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.7744e-05 - mae: 0.0041 - val_loss: 5.0797e-06 - val_mae: 0.0015\n",
            "Epoch 385/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.6417e-05 - mae: 0.0032 - val_loss: 1.2443e-05 - val_mae: 0.0026\n",
            "Epoch 386/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1164e-05 - mae: 0.0023 - val_loss: 5.5221e-05 - val_mae: 0.0054\n",
            "Epoch 387/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.1908e-05 - mae: 0.0049 - val_loss: 1.7607e-05 - val_mae: 0.0031\n",
            "Epoch 388/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.6758e-05 - mae: 0.0052 - val_loss: 3.0599e-05 - val_mae: 0.0038\n",
            "Epoch 389/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.1417e-05 - mae: 0.0051 - val_loss: 1.2152e-04 - val_mae: 0.0079\n",
            "Epoch 390/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.5828e-05 - mae: 0.0064 - val_loss: 1.0030e-05 - val_mae: 0.0021\n",
            "Epoch 391/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0384e-05 - mae: 0.0037 - val_loss: 2.0682e-04 - val_mae: 0.0106\n",
            "Epoch 392/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7758e-05 - mae: 0.0054 - val_loss: 1.6610e-05 - val_mae: 0.0029\n",
            "Epoch 393/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.0638e-05 - mae: 0.0045 - val_loss: 7.7123e-05 - val_mae: 0.0060\n",
            "Epoch 394/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.8565e-05 - mae: 0.0040 - val_loss: 2.1400e-04 - val_mae: 0.0106\n",
            "Epoch 395/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0791e-04 - mae: 0.0068 - val_loss: 2.0075e-05 - val_mae: 0.0031\n",
            "Epoch 396/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.2539e-05 - mae: 0.0051 - val_loss: 2.7664e-05 - val_mae: 0.0034\n",
            "Epoch 397/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.3244e-05 - mae: 0.0025 - val_loss: 2.3805e-05 - val_mae: 0.0036\n",
            "Epoch 398/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.9219e-05 - mae: 0.0046 - val_loss: 4.2106e-05 - val_mae: 0.0042\n",
            "Epoch 399/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.4222e-04 - mae: 0.0096 - val_loss: 1.7768e-05 - val_mae: 0.0030\n",
            "Epoch 400/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6077e-05 - mae: 0.0028 - val_loss: 3.3941e-05 - val_mae: 0.0035\n",
            "Epoch 401/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.9364e-05 - mae: 0.0034 - val_loss: 1.7414e-04 - val_mae: 0.0089\n",
            "Epoch 402/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.2017e-05 - mae: 0.0058 - val_loss: 1.2711e-05 - val_mae: 0.0025\n",
            "Epoch 403/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5306e-05 - mae: 0.0034 - val_loss: 1.0947e-04 - val_mae: 0.0064\n",
            "Epoch 404/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.3336e-05 - mae: 0.0047 - val_loss: 2.0399e-05 - val_mae: 0.0032\n",
            "Epoch 405/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.4846e-05 - mae: 0.0041 - val_loss: 8.1600e-05 - val_mae: 0.0063\n",
            "Epoch 406/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.9525e-05 - mae: 0.0048 - val_loss: 1.2159e-05 - val_mae: 0.0023\n",
            "Epoch 407/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0443e-05 - mae: 0.0031 - val_loss: 7.8075e-05 - val_mae: 0.0066\n",
            "Epoch 408/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.7958e-04 - mae: 0.0089 - val_loss: 3.4589e-05 - val_mae: 0.0042\n",
            "Epoch 409/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.7417e-05 - mae: 0.0051 - val_loss: 5.3721e-06 - val_mae: 0.0015\n",
            "Epoch 410/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2642e-05 - mae: 0.0024 - val_loss: 9.5125e-06 - val_mae: 0.0022\n",
            "Epoch 411/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7037e-05 - mae: 0.0027 - val_loss: 3.8523e-05 - val_mae: 0.0045\n",
            "Epoch 412/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.8081e-05 - mae: 0.0036 - val_loss: 4.8604e-05 - val_mae: 0.0050\n",
            "Epoch 413/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1083e-04 - mae: 0.0067 - val_loss: 2.7917e-05 - val_mae: 0.0038\n",
            "Epoch 414/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.2707e-05 - mae: 0.0056 - val_loss: 2.7519e-05 - val_mae: 0.0038\n",
            "Epoch 415/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.6934e-05 - mae: 0.0045 - val_loss: 1.2422e-04 - val_mae: 0.0079\n",
            "Epoch 416/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.1629e-04 - mae: 0.0068 - val_loss: 1.3986e-05 - val_mae: 0.0025\n",
            "Epoch 417/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5751e-05 - mae: 0.0028 - val_loss: 1.8086e-05 - val_mae: 0.0033\n",
            "Epoch 418/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.2150e-05 - mae: 0.0038 - val_loss: 2.7204e-05 - val_mae: 0.0040\n",
            "Epoch 419/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0003e-05 - mae: 0.0027 - val_loss: 5.3060e-04 - val_mae: 0.0145\n",
            "Epoch 420/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.1196e-04 - mae: 0.0157 - val_loss: 2.5749e-05 - val_mae: 0.0036\n",
            "Epoch 421/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0630e-05 - mae: 0.0031 - val_loss: 6.1892e-06 - val_mae: 0.0017\n",
            "Epoch 422/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.0742e-06 - mae: 0.0018 - val_loss: 1.1345e-05 - val_mae: 0.0024\n",
            "Epoch 423/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.9544e-06 - mae: 0.0018 - val_loss: 7.3458e-06 - val_mae: 0.0019\n",
            "Epoch 424/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.5395e-06 - mae: 0.0019 - val_loss: 1.0854e-05 - val_mae: 0.0024\n",
            "Epoch 425/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.4438e-05 - mae: 0.0037 - val_loss: 1.6126e-05 - val_mae: 0.0030\n",
            "Epoch 426/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.8641e-05 - mae: 0.0034 - val_loss: 2.4821e-04 - val_mae: 0.0107\n",
            "Epoch 427/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6356e-04 - mae: 0.0109 - val_loss: 1.6642e-05 - val_mae: 0.0030\n",
            "Epoch 428/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4835e-05 - mae: 0.0027 - val_loss: 4.7615e-06 - val_mae: 0.0016\n",
            "Epoch 429/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.5502e-06 - mae: 0.0016 - val_loss: 4.8510e-06 - val_mae: 0.0015\n",
            "Epoch 430/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.2385e-06 - mae: 0.0019 - val_loss: 1.7510e-05 - val_mae: 0.0030\n",
            "Epoch 431/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6076e-05 - mae: 0.0027 - val_loss: 4.6989e-06 - val_mae: 0.0015\n",
            "Epoch 432/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.2061e-05 - mae: 0.0032 - val_loss: 1.5147e-05 - val_mae: 0.0029\n",
            "Epoch 433/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5255e-05 - mae: 0.0027 - val_loss: 1.1988e-05 - val_mae: 0.0027\n",
            "Epoch 434/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.6535e-05 - mae: 0.0041 - val_loss: 2.6839e-05 - val_mae: 0.0037\n",
            "Epoch 435/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.6610e-05 - mae: 0.0062 - val_loss: 6.3350e-05 - val_mae: 0.0051\n",
            "Epoch 436/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.6120e-05 - mae: 0.0046 - val_loss: 5.9614e-06 - val_mae: 0.0016\n",
            "Epoch 437/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9.2962e-06 - mae: 0.0021 - val_loss: 2.1017e-05 - val_mae: 0.0033\n",
            "Epoch 438/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.8545e-05 - mae: 0.0045 - val_loss: 1.0744e-04 - val_mae: 0.0066\n",
            "Epoch 439/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3500e-04 - mae: 0.0071 - val_loss: 1.0256e-04 - val_mae: 0.0077\n",
            "Epoch 440/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0627e-04 - mae: 0.0069 - val_loss: 6.1765e-04 - val_mae: 0.0161\n",
            "Epoch 441/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.5711e-04 - mae: 0.0071 - val_loss: 3.7822e-06 - val_mae: 0.0013\n",
            "Epoch 442/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.0607e-06 - mae: 0.0015 - val_loss: 7.1083e-06 - val_mae: 0.0020\n",
            "Epoch 443/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4255e-06 - mae: 0.0020 - val_loss: 1.6273e-05 - val_mae: 0.0030\n",
            "Epoch 444/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.3010e-05 - mae: 0.0033 - val_loss: 7.9640e-05 - val_mae: 0.0056\n",
            "Epoch 445/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.9177e-05 - mae: 0.0050 - val_loss: 7.1403e-06 - val_mae: 0.0020\n",
            "Epoch 446/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0726e-05 - mae: 0.0022 - val_loss: 9.2437e-05 - val_mae: 0.0071\n",
            "Epoch 447/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.0923e-05 - mae: 0.0066 - val_loss: 9.7468e-06 - val_mae: 0.0022\n",
            "Epoch 448/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3795e-05 - mae: 0.0030 - val_loss: 9.5482e-06 - val_mae: 0.0020\n",
            "Epoch 449/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.1435e-05 - mae: 0.0051 - val_loss: 4.3429e-04 - val_mae: 0.0135\n",
            "Epoch 450/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4029e-04 - mae: 0.0078 - val_loss: 6.8766e-06 - val_mae: 0.0019\n",
            "Epoch 451/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.5278e-06 - mae: 0.0020 - val_loss: 4.0023e-06 - val_mae: 0.0013\n",
            "Epoch 452/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3170e-06 - mae: 0.0014 - val_loss: 7.4945e-06 - val_mae: 0.0020\n",
            "Epoch 453/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4861e-05 - mae: 0.0022 - val_loss: 9.0640e-05 - val_mae: 0.0065\n",
            "Epoch 454/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0320e-04 - mae: 0.0067 - val_loss: 9.7396e-06 - val_mae: 0.0019\n",
            "Epoch 455/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1046e-05 - mae: 0.0023 - val_loss: 1.9169e-05 - val_mae: 0.0034\n",
            "Epoch 456/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4935e-05 - mae: 0.0026 - val_loss: 1.2886e-04 - val_mae: 0.0084\n",
            "Epoch 457/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.1579e-05 - mae: 0.0065 - val_loss: 2.3844e-05 - val_mae: 0.0034\n",
            "Epoch 458/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.3029e-04 - mae: 0.0073 - val_loss: 1.0547e-05 - val_mae: 0.0026\n",
            "Epoch 459/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.1885e-05 - mae: 0.0024 - val_loss: 7.7668e-06 - val_mae: 0.0019\n",
            "Epoch 460/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.2344e-05 - mae: 0.0028 - val_loss: 1.0406e-04 - val_mae: 0.0067\n",
            "Epoch 461/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.3207e-05 - mae: 0.0063 - val_loss: 6.5474e-05 - val_mae: 0.0059\n",
            "Epoch 462/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.6548e-05 - mae: 0.0043 - val_loss: 5.3986e-05 - val_mae: 0.0055\n",
            "Epoch 463/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.9052e-05 - mae: 0.0038 - val_loss: 1.4492e-05 - val_mae: 0.0025\n",
            "Epoch 464/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1259e-05 - mae: 0.0029 - val_loss: 1.6469e-04 - val_mae: 0.0086\n",
            "Epoch 465/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.0004e-05 - mae: 0.0047 - val_loss: 4.4150e-05 - val_mae: 0.0047\n",
            "Epoch 466/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.9620e-05 - mae: 0.0050 - val_loss: 3.7391e-04 - val_mae: 0.0144\n",
            "Epoch 467/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2589e-04 - mae: 0.0115 - val_loss: 1.4670e-05 - val_mae: 0.0028\n",
            "Epoch 468/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8206e-05 - mae: 0.0028 - val_loss: 7.2597e-06 - val_mae: 0.0019\n",
            "Epoch 469/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.5042e-06 - mae: 0.0020 - val_loss: 7.6897e-06 - val_mae: 0.0020\n",
            "Epoch 470/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5490e-06 - mae: 0.0015 - val_loss: 4.0865e-06 - val_mae: 0.0014\n",
            "Epoch 471/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.9552e-06 - mae: 0.0018 - val_loss: 1.9382e-05 - val_mae: 0.0027\n",
            "Epoch 472/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1714e-04 - mae: 0.0060 - val_loss: 2.7116e-05 - val_mae: 0.0036\n",
            "Epoch 473/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.2356e-05 - mae: 0.0024 - val_loss: 1.1172e-05 - val_mae: 0.0024\n",
            "Epoch 474/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6471e-05 - mae: 0.0028 - val_loss: 1.0098e-05 - val_mae: 0.0025\n",
            "Epoch 475/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6281e-05 - mae: 0.0032 - val_loss: 4.8321e-05 - val_mae: 0.0049\n",
            "Epoch 476/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.3226e-05 - mae: 0.0050 - val_loss: 1.3035e-05 - val_mae: 0.0026\n",
            "Epoch 477/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.6898e-05 - mae: 0.0032 - val_loss: 5.8692e-05 - val_mae: 0.0052\n",
            "Epoch 478/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2684e-04 - mae: 0.0071 - val_loss: 5.4419e-06 - val_mae: 0.0018\n",
            "Epoch 479/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.2599e-05 - mae: 0.0024 - val_loss: 4.9577e-06 - val_mae: 0.0015\n",
            "Epoch 480/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.1925e-05 - mae: 0.0021 - val_loss: 7.4019e-05 - val_mae: 0.0061\n",
            "Epoch 481/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.5004e-05 - mae: 0.0056 - val_loss: 5.6147e-05 - val_mae: 0.0059\n",
            "Epoch 482/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.2087e-05 - mae: 0.0060 - val_loss: 6.2202e-05 - val_mae: 0.0053\n",
            "Epoch 483/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2257e-05 - mae: 0.0039 - val_loss: 6.6628e-06 - val_mae: 0.0019\n",
            "Epoch 484/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.7289e-06 - mae: 0.0020 - val_loss: 7.4603e-06 - val_mae: 0.0019\n",
            "Epoch 485/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9420e-05 - mae: 0.0028 - val_loss: 1.1913e-05 - val_mae: 0.0023\n",
            "Epoch 486/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.5330e-05 - mae: 0.0030 - val_loss: 1.4042e-04 - val_mae: 0.0085\n",
            "Epoch 487/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.7995e-05 - mae: 0.0060 - val_loss: 4.8681e-05 - val_mae: 0.0045\n",
            "Epoch 488/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4244e-05 - mae: 0.0041 - val_loss: 7.4441e-06 - val_mae: 0.0018\n",
            "Epoch 489/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.5793e-05 - mae: 0.0040 - val_loss: 6.0878e-05 - val_mae: 0.0060\n",
            "Epoch 490/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0694e-05 - mae: 0.0051 - val_loss: 7.4697e-06 - val_mae: 0.0020\n",
            "Epoch 491/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.3664e-05 - mae: 0.0032 - val_loss: 4.0490e-06 - val_mae: 0.0014\n",
            "Epoch 492/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6073e-05 - mae: 0.0029 - val_loss: 2.3595e-04 - val_mae: 0.0114\n",
            "Epoch 493/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6646e-04 - mae: 0.0083 - val_loss: 9.6215e-06 - val_mae: 0.0022\n",
            "Epoch 494/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.8915e-06 - mae: 0.0019 - val_loss: 3.6065e-06 - val_mae: 0.0013\n",
            "Epoch 495/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.4259e-06 - mae: 0.0016 - val_loss: 8.8013e-06 - val_mae: 0.0022\n",
            "Epoch 496/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.7306e-06 - mae: 0.0019 - val_loss: 6.1977e-06 - val_mae: 0.0019\n",
            "Epoch 497/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9033e-06 - mae: 0.0019 - val_loss: 2.7967e-05 - val_mae: 0.0032\n",
            "Epoch 498/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.1641e-05 - mae: 0.0032 - val_loss: 1.1139e-04 - val_mae: 0.0077\n",
            "Epoch 499/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8.6822e-05 - mae: 0.0064 - val_loss: 6.9122e-05 - val_mae: 0.0062\n",
            "Epoch 500/500\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 8.7246e-05 - mae: 0.0060 - val_loss: 5.1024e-04 - val_mae: 0.0135\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
            "Input: [24.93625511  8.67514603 -1.42296288 -2.36409353  8.85690079  0.94113065\n",
            " 18.85690079]\n",
            "True Output: [0.7        0.         0.47056532]\n",
            "Predicted Output: [ 0.6979603  -0.00267635  0.44742665]\n",
            "--------------------------------------------------\n",
            "Input: [23.16844673 17.76751392 -0.41326429 -1.12994448  2.05591463  0.71668019\n",
            " 12.05591463]\n",
            "True Output: [0.7       0.        0.3583401]\n",
            "Predicted Output: [ 0.70842737 -0.00261423  0.31716636]\n",
            "--------------------------------------------------\n",
            "Input: [28.1725358  14.31392714  1.95737604  1.3199125  -2.79539241  0.63746354\n",
            "  7.20460759]\n",
            "True Output: [0.         0.27953924 0.31873177]\n",
            "Predicted Output: [0.0101255  0.27874577 0.28637454]\n",
            "--------------------------------------------------\n",
            "Input: [17.62603395 18.74460664 -1.79298319 -2.01335888  2.78980352  0.22037569\n",
            " 12.78980352]\n",
            "True Output: [0.7        0.         0.11018784]\n",
            "Predicted Output: [ 0.7066797  -0.00244785  0.06999407]\n",
            "--------------------------------------------------\n",
            "Input: [23.36029767  9.65350437 -1.81867309 -1.19365286 -3.19110702 -0.62502023\n",
            "  6.80889298]\n",
            "True Output: [ 0.          0.3191107  -0.31251012]\n",
            "Predicted Output: [ 0.01065953  0.3179284  -0.3313433 ]\n",
            "--------------------------------------------------\n",
            "Input: [13.09234291 22.6369963  -2.13043151 -0.1549234  -4.24155604 -1.97550811\n",
            "  5.75844396]\n",
            "True Output: [ 0.          0.4241556  -0.98775406]\n",
            "Predicted Output: [ 0.01058139  0.42553514 -1.0210487 ]\n",
            "--------------------------------------------------\n",
            "Input: [21.71298476 22.70633329 -1.53532449 -3.13703859  8.92704298  1.6017141\n",
            " 18.92704298]\n",
            "True Output: [0.7        0.         0.80085705]\n",
            "Predicted Output: [ 0.70497125 -0.00289772  0.7603329 ]\n",
            "--------------------------------------------------\n",
            "Input: [ 2.77528461  9.50939983 -1.12097598  2.61029655 -2.22450612  2.55191278\n",
            "  7.77549388]\n",
            "True Output: [0.         0.22245061 1.        ]\n",
            "Predicted Output: [-0.00153817  0.22684625  0.9992095 ]\n",
            "--------------------------------------------------\n",
            "Input: [29.48089006 12.30087617  2.27235114 -0.94372586 -1.25334195 -3.06710831\n",
            "  8.74665805]\n",
            "True Output: [ 0.         0.1253342 -1.       ]\n",
            "Predicted Output: [ 0.01262631  0.12626313 -1.0311899 ]\n",
            "--------------------------------------------------\n",
            "Input: [24.28508451 28.14480615 -1.82589445  1.69691123 -2.63488868  2.76037963\n",
            "  7.36511132]\n",
            "True Output: [0.         0.26348887 1.        ]\n",
            "Predicted Output: [0.01153176 0.26470196 0.94605535]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save to a file\n",
        "with open(\"platooning_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "zm7_zbJ9AsZr",
        "outputId": "cfb67a7c-f893-4c38-c4f7-d48096e89473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpvqustf5r'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 7), dtype=tf.float32, name='keras_tensor_3')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135425038804672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135425038809600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135425020004304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135425020003952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135425038804848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135425020002368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135425020009232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135425020010464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135425020011520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135425020013984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZX9qDrAAs2s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}